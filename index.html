<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yufeng Yue</title>
  
  <meta name="author" content=" Yufeng Yue">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    #mmvst_globe {
        width: 300px; /* 设置地球的宽度 */
        height: 300px; /* 设置地球的高度 */
    }
  </style>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Yufeng Yue | 岳裕丰</name>
              </p>
              <p>
		I am a Professor in the School of Automation, Beijing Institute of Technology. I received the B.Eng. degree in automation from the Beijing Institute of Technology in 2014, and the Ph.D. degree in robotics from Nanyang Technological University in 2019. After That, I was a Postdoc with Nanyang Technological University from 2018-2020. During my Postdoc, I was an visiting assitante research with University of California, Los Angeles in 2019. I joined Beijing Institute of Technology in 2020.

              </p>
              </p>
              <p style="text-align:center">
                <a href="mailto: yueyufeng@bit.edu.cn">Email</a> &nbsp/&nbsp
                <a href=" https://scholar.google.com/citations?user=7M_xficAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Yufeng-Yue">Research Gate</a>

              </p>
            </td>
            <td style="padding:2.5%;width:50%;max-width:50%">
              <a href="images/yufeng.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="images/yufeng.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
		Our research goal is to enhance the autonomy and generalization of robotic systems in open environments. By leveraging cross-disciplinary knowledge such as deep learning, robotics, and control, our research interests lies on: Spatial-AI perception, Cognitive navigation, cross-embodiment intelligence. We have developed a variety of robot systems that operate in structured/semi-structured/field environments. 
 </p>

  <p>
We are looking for candidates who have strong self-motivation, intense interest in robotic systems, and desire to combine artificial intelligence with practical robotics systems. For prospective students: If you are interested in working with us as a Master/PhD student or intership student, please feel free to contact me.

              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <img src='images/opengraph.jpg' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments</papertitle>
              <br>
	      <a>Yinan Deng</a>,
              <a> Jiahui Wang</a>,
              <a> Jingyu Zhao</a>,
              <a> Xinyu Tian</a>,
              <a> Guangyan Chen</a>,
              <a>Yi Yang</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>Arxiv 2024</em>
              <br>
              <a href=https://arxiv.org/pdf/2403.09412.pdf>[PDF]</a> 
              <a href="https://arxiv.org/abs/2403.09412">[Arxiv]</a> 
              <a href="https://github.com/BIT-DYN/OpenGraph">[Code]</a> 
              <p></p>
            </td>
         </tr>

          
          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <img src='images/macim.jpg' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>MACIM: Multi-Agent Collaborative Implicit Mapping</papertitle>
              <br>
	      <a>Yinan Deng</a>,
              <a> Yujie Tang</a>,
              <a>Yi Yang</a>,
              <a>Danwei Wang</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>IEEE Robotics and Automation Letters (RAL) 2024</em>
              <br>
              <a href=https://drive.google.com/file/d/1Y0tJIY4uLdCNG98D8oiAl4SN65uC9Aff/view>[PDF]</a> 
              <a href="https://ieeexplore.ieee.org/document/10476626">[IEEE]</a> 
              <a href="https://github.com/BIT-DYN/MACIM">[Code]</a> 
              <p></p>
            </td>
         </tr>


          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <img src='images/see-csom.jpg' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>SEE-CSOM: Sharp-Edged and Efficient Continuous Semantic Occupancy Mapping for Mobile Robots</papertitle>
              <br>
	      <a>Yinan Deng</a>,
              <a> Meiling Wang</a>,
              <a>Yi Yang</a>,
              <a>Danwei Wang</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>IEEE Transactions on Industrial Electronics (TIE) 2024</em>
              <br>
              <a href=https://drive.google.com/file/d/1vji6cXKYuk5F8sI14og4HjPpiCddPoaS/view?usp=drive_link>[PDF]</a> 
              <a href=https://ieeexplore.ieee.org/document/10093797">[IEEE]</a> 
              <a href="https://github.com/BIT-DYN/SEE-CSOM">[Code]</a> 
              <p></p>
            </td>
         </tr>

<tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <img src='images/tang2023tmech.jpg' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <br>
	      <a>Yujie Tang</a >,
              <a> Meiling Wang</a >,
	      <a> Yi Yang </a >,
              <a> Ziquan Lan </a >,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>TMech 2023</em>
              <br> 
              <a https://ieeexplore.ieee.org/abstract/document/10348021">[IEEE]</a > 
              <p></p >
            </td>
         </tr>

          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <img src='images/HORCL.jpg' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Multi-View Robust Collaborative Localization in High Outlier Ratio Scenes Based on Semantic Features</papertitle>
              <br>
	      <a>Yujie Tang</a>,
              <a> Meiling Wang</a>,
	      <a>Yinan Deng</a>,
              <a>Yi Yang</a>,
              <a>Ziquan Lan</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>IROS 2023</em>
              <br>
              <a href=https://drive.google.com/file/d/1tJfo73CLZdGeB0jxwlJei6UmEks6PU72/view?usp=drive_link>[PDF]</a> 
              <a href=https://ieeexplore.ieee.org/abstract/document/10342524">[IEEE]</a> 
              <a href="https://github.com/BIT-TYJ/HORCL">[Code]</a> 
              <p></p>
            </td>
         </tr>

          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <img src='images/ssgm.jpg' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>SSGM: Spatial Semantic Graph Matching for Loop Closure Detection in Indoor Environments</papertitle>
              <br>
	      <a>Yujie Tang</a>,
              <a> Meiling Wang</a>,
	      <a>Yinan Deng</a>,
              <a>Yi Yang</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>IROS 2023</em>
              <br>
              <a href=https://drive.google.com/file/d/17sVx9W4QnUkjaMr61PFwpuxzT1yml2uX/view?usp=drive_link>[PDF]</a> 
              <a href=https://ieeexplore.ieee.org/abstract/document/10342317">[IEEE]</a> 
              <a href="https://github.com/BIT-TYJ/SSGM">[Code]</a> 
              <p></p>
            </td>
         </tr>

          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <video style="width:100%;height:100%;object-fit:fill" id="main-video" autobuffer muted autoplay loop controls>
                <source src="videos/hd-ccsom.mp4" type="video/mp4">
              </video>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>HD-CCSOM: Hierarchical and Dense Collaborative Continuous Semantic Occupancy Mapping through Label Diffusion</papertitle>
              <br>
	      <a>Yinan Deng</a>,
              <a> Meiling Wang</a>,
              <a>Yi Yang</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>IROS 2022</em>
              <br>
              <a href=https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9981756>[PDF]</a> 
              <a href=https://ieeexplore.ieee.org/abstract/document/9981756">[IEEE]</a> 
              <a href="https://github.com/BIT-DYN/HD-CCSOM">[Code]</a> 
              <p></p>
            </td>
         </tr>


          <tr>
            <td style="padding:10px;width:40%;vertical-align:middle">
              <video style="width:100%;height:100%;object-fit:fill" id="main-video" autobuffer muted autoplay loop controls>
                <source src="videos/s-mki.mp4" type="video/mp4">
              </video>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>S-MKI: Incremental Dense Semantic Occupancy Reconstruction Through Multi-Entropy Kernel Inference</papertitle>
              <br>
	      <a>Yinan Deng</a>,
              <a> Meiling Wang</a>,
              <a>Danwei Wang</a>,
              <strong>Yufeng Yue</strong>,
              <br>
              <em>IROS 2022</em>
              <br>
              <a href=https://drive.google.com/file/d/16fpqzUqQAHrn9fpw3qczrCvaX6Hfaisz/view?pli=1>[PDF]</a> 
              <a href=https://ieeexplore.ieee.org/abstract/document/9982101">[IEEE]</a> 
              <p></p>
            </td>
         </tr>
       
      </td>
    </tr>
  </table>
</body>

</html>
